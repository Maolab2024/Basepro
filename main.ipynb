{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112ff68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: extract.py [-h] [--toks_per_batch TOKS_PER_BATCH]\n",
      "                  [--repr_layers REPR_LAYERS [REPR_LAYERS ...]] --include\n",
      "                  {mean,per_tok,bos,contacts}\n",
      "                  [{mean,per_tok,bos,contacts} ...]\n",
      "                  [--truncation_seq_length TRUNCATION_SEQ_LENGTH] [--nogpu]\n",
      "                  [--concatenate_dir CONCATENATE_DIR]\n",
      "                  model_location fasta_file output_dir\n",
      "\n",
      "Extract per-token representations and model outputs for sequences in a FASTA\n",
      "file\n",
      "\n",
      "positional arguments:\n",
      "  model_location        PyTorch model file OR name of pretrained model to\n",
      "                        download (see README for models)\n",
      "  fasta_file            FASTA file on which to extract representations\n",
      "  output_dir            output directory for extracted representations\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --toks_per_batch TOKS_PER_BATCH\n",
      "                        maximum batch size\n",
      "  --repr_layers REPR_LAYERS [REPR_LAYERS ...]\n",
      "                        layers indices from which to extract representations\n",
      "                        (0 to num_layers, inclusive)\n",
      "  --include {mean,per_tok,bos,contacts} [{mean,per_tok,bos,contacts} ...]\n",
      "                        specify which representations to return\n",
      "  --truncation_seq_length TRUNCATION_SEQ_LENGTH\n",
      "                        truncate sequences longer than the given value\n",
      "  --nogpu               Do not use GPU even if available\n",
      "  --concatenate_dir CONCATENATE_DIR\n",
      "                        output directory for concatenated representations\n"
     ]
    }
   ],
   "source": [
    "!python src/esm/extract.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214a8159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download over\n",
      "Transferred model to GPU\n",
      "Read data/p1450.fasta with 3 sequences\n",
      "Processing 1 of 2 batches (2 sequences)\n",
      "Device: cuda:0\n",
      "Processing 2 of 2 batches (1 sequences)\n",
      "Device: cuda:0\n",
      "Saved representations to data/esm_embedings/P1450\n",
      "/data/home/maorunzegroup/Basepro/src/esm/extract.py:206: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  file_data = torch.load(file_path)\n",
      "Shape of concatenated DataFrame: (3, 1280)\n",
      "Saved concatenated representations to /data/home/maorunzegroup/Basepro/data/esm_embedings/p1450_esm1b_t33_650M_UR50S.csv\n"
     ]
    }
   ],
   "source": [
    "!python src/esm/extract.py esm1b_t33_650M_UR50S data/p1450.fasta data/esm_embedings/P1450 --toks_per_batch 512 --include mean --concatenate_dir /data/home/maorunzegroup/Basepro/data/esm_embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79026924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb7b75",
   "metadata": {},
   "source": [
    "### round_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample_csv(input_file_path,saved_file_path,sample_size=200):\n",
    "    \"\"\"\n",
    "    Randomly samples rows from a large CSV file and saves to a new file as round0 data.\n",
    "    \n",
    "    Parameters:\n",
    "    input_file_path (str): Path to input CSV file\n",
    "    saved_file_path (str): Path to save the sampled CSV file\n",
    "    sample_size (int): Number of rows to sample (default: 200)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        print(f\"Reading file: {os.path.basename(input_file_path)}...\")\n",
    "        df = pd.read_csv(input_file_path)\n",
    "        \n",
    "        # Validate file size\n",
    "        if len(df) < sample_size:\n",
    "            print(f\"Warning: File has only {len(df)} rows, less than requested sample size {sample_size}\")\n",
    "            sample_size = len(df)\n",
    "        \n",
    "        # Perform random sampling\n",
    "        np.random.seed(42)  \n",
    "        round0_indices = np.random.choice(len(df), size=sample_size, replace=False)\n",
    "\n",
    "        sampled_df = pd.DataFrame()\n",
    "        sampled_df['variant'] = df['variant'][round0_indices]  # Fixed seed for reproducibility\n",
    "        sampled_df['fitness'] = df['fitness'][round0_indices]\n",
    "        sampled_df['indices'] = round0_indices\n",
    "        # Save sampled data\n",
    "        sampled_df.to_csv(saved_file_path, index=False)\n",
    "        print(f\"✓ Sampling complete! Saved to: {saved_file_path}\")\n",
    "        print(f\"Original rows: {len(df)}, Sampled rows: {len(sampled_df)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Operation failed. Please check file path and format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54f6519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: fitness.csv...\n",
      "✓ Sampling complete! Saved to: rounds_data/GB1/GB1_round_0.csv\n",
      "Original rows: 149361, Sampled rows: 200\n"
     ]
    }
   ],
   "source": [
    "random_sample_csv('data/GB1/fitness.csv', 'rounds_data/GB1/GB1_round_0.csv', sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f9761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_name = 'GB1'\n",
    "embeddings_base_path = 'data/GB1'\n",
    "embeddings_file_name = 'ESM2_x.pt'\n",
    "round_base_path = 'rounds_data/GB1'\n",
    "number_of_variants = 90\n",
    "output_dir = 'output'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccb3eb",
   "metadata": {},
   "source": [
    "### round_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4975a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import run_directed_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44164789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "round_base_path = 'rounds_data/GB1'\n",
    "round_name = 'round_1'\n",
    "round_data_filenames = [\n",
    "    'GB1_round_0.csv',\n",
    "    # 'GB1_round_1.csv'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e6c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = pd.read_csv('data/GB1/fitness.csv')\n",
    "all_variants = pd.DataFrame({\n",
    "    'variant': fitness['variant'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1d7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739dd082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GB1 - round_1\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/maorunzegroup/Basepro/src/data.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings from data/GB1/ESM2_x.pt with shape torch.Size([149361, 5120])\n",
      "Embeddings loaded: torch.Size([149361, 5120])\n",
      "Loaded: GB1_round_0.csv (Round 0)\n",
      "\n",
      "Top 90 variants predicted by the modelf or next round: 90\n",
      "       variant   fitness  indices\n",
      "104538    WYAG  2.455739   104538\n",
      "82283     YIAG  2.291723    82283\n",
      "30244     WFAG  2.289244    30244\n",
      "80659     YFAG  2.273627    80659\n",
      "35767     TIAG  2.248921    35767\n",
      "...        ...       ...      ...\n",
      "115498    IGAG  1.632279   115498\n",
      "7548      LGAG  1.628683     7548\n",
      "20533     KVAG  1.624723    20533\n",
      "10104     IVGG  1.621714    10104\n",
      "77161     KICG  1.621399    77161\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "\n",
      "Data saved to output/GB1/round_1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_next_round, df_pre_all_sorted = run_directed_evolution(\n",
    "    protein_name,\n",
    "    round_name,\n",
    "    embeddings_base_path,\n",
    "    embeddings_file_name,\n",
    "    round_base_path,\n",
    "    round_data_filenames,\n",
    "    number_of_variants,\n",
    "    output_dir,\n",
    "    regression_model='xgboost',\n",
    "    all_variants=all_variants\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf37ce",
   "metadata": {},
   "source": [
    "## round2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39fd99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "round_base_path = 'rounds_data/GB1'\n",
    "round_name = 'round_2'\n",
    "round_data_filenames = [\n",
    "    'GB1_round_0.csv',\n",
    "    'GB1_round_1.csv'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a2e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GB1 - round_2\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/maorunzegroup/Basepro/src/data.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings from data/GB1/ESM2_x.pt with shape torch.Size([149361, 5120])\n",
      "Embeddings loaded: torch.Size([149361, 5120])\n",
      "Loaded: GB1_round_0.csv (Round 0)\n",
      "Loaded: GB1_round_1.csv (Round 1)\n",
      "\n",
      "Top 90 variants predicted by the modelf or next round: 90\n",
      "       variant   fitness  indices\n",
      "102915    WIGG  1.971513   102915\n",
      "97910     IYIG  1.936826    97910\n",
      "126925    ITVG  1.916372   126925\n",
      "24555     YTAG  1.910432    24555\n",
      "89858     YTPG  1.904741    89858\n",
      "...        ...       ...      ...\n",
      "119817    YNPG  1.760194   119817\n",
      "92992     WCNG  1.759691    92992\n",
      "84732     GKVG  1.759637    84732\n",
      "86641     WEGG  1.758777    86641\n",
      "50471     WSPG  1.757703    50471\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "\n",
      "Data saved to output/GB1/round_2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_next_round, df_pre_all_sorted = run_directed_evolution(\n",
    "    protein_name,\n",
    "    round_name,\n",
    "    embeddings_base_path,\n",
    "    embeddings_file_name,\n",
    "    round_base_path,\n",
    "    round_data_filenames,\n",
    "    number_of_variants,\n",
    "    output_dir,\n",
    "    regression_model='xgboost',\n",
    "    all_variants=all_variants\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evolvepro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
